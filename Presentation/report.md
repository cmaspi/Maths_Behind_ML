# Probabilistic PCA
### Chirag Mehta
## Abstract
Principal Component Analysis (PCA) is a widely used method for analyzing and processing data, although it lacks a foundation in a probability model. In this paper, I showcase the utilization of maximum-likelihood estimation in a latent variable model closely linked to factor analysis to identify the principal axes of observed data vectors. We explore the characteristics of the corresponding likelihood function and highlight the benefits offered by this probabilistic approach through illustrative examples.

## Introduction

## Mathematical Background
1. Definition of multivariate gaussian:
A random vector is said to be *k-variate* normally distributed if every linear combination of its k components has a univariate normal distribution.

2. Affine Transformation: 
$$
\begin{align}
X \sim \mathcal{N}\left(\mu, \Sigma\right)
\end{align}
$$
Then
$$
\begin{align}
AX+b \sim \mathcal{N}\left(A\mu+b, A\Sigma A^T\right)
\end{align}
$$

3. 

## 
